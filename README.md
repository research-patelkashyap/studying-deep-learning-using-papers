# Studying Deep Learning Through Seminal and Modern Research Papers

**Prerequisite:**
1. Machine Learning: [https://arxiv.org/pdf/2310.11470](https://arxiv.org/pdf/2310.11470)
1. Matrix Calculus: [https://arxiv.org/abs/1802.01528](https://arxiv.org/abs/1802.01528)

## 1. Introduction

1. Introduction to deep learning 1: [https://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf](https://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf)
2. Introduction to deep learning 2 (Optional): [https://arxiv.org/abs/2003.03253](https://arxiv.org/abs/2003.03253)
3. Backpropagation (Read after studying neural network architectures): [https://arxiv.org/abs/2301.09977](https://arxiv.org/abs/2301.09977)

## 2. Optimization

1. Optimization in Machine Learning (Survey): [https://arxiv.org/abs/2501.14458](https://arxiv.org/abs/2501.14458)
2. AdaGrad: [https://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf](https://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf)
3. RMSProp: [https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf](https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf)
4. ADADELTA: [https://arxiv.org/abs/1212.5701](https://arxiv.org/abs/1212.5701)
5. Adam: [https://arxiv.org/abs/1412.6980](https://arxiv.org/abs/1412.6980)
6. On the Convergence of Adam and Adagrad: [https://arxiv.org/abs/2003.02395](https://arxiv.org/abs/2003.02395)

## 3. Neural Network Architectures

1. CNN 1: [https://arxiv.org/abs/2408.12308](https://arxiv.org/abs/2408.12308)
2. CNN 2: [https://arxiv.org/abs/1603.07285](https://arxiv.org/abs/1603.07285)
3. RNN 1: [https://arxiv.org/abs/1912.05911](https://arxiv.org/abs/1912.05911)
4. LSTM: [https://arxiv.org/abs/1909.09586](https://arxiv.org/abs/1909.09586)
5. GRU: [https://arxiv.org/abs/1909.09586](https://arxiv.org/abs/1909.09586)
6. Bidirectional RNN: [https://ieeexplore.ieee.org/document/650093](https://ieeexplore.ieee.org/document/650093)
7. RNN 2: [https://arxiv.org/abs/1409.0473](https://arxiv.org/abs/1409.0473)
8. Transformer 1: [https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762)
9. Transformer 2: [https://arxiv.org/abs/2207.09238](https://arxiv.org/abs/2207.09238)
10. GNN: [https://arxiv.org/abs/2010.05234](https://arxiv.org/abs/2010.05234)

## 4. Regularization Techniques

1. A Taxonomy of Regularization Techniques: [https://arxiv.org/abs/1710.10686](https://arxiv.org/abs/1710.10686)
2. Regularization in Convolutional Neural Networks: [https://arxiv.org/abs/2201.03299](https://arxiv.org/abs/2201.03299)
3. Regularization in Recurrent Neural Networks: [https://arxiv.org/abs/1409.2329](https://arxiv.org/abs/1409.2329)

## 5. Explainability in ML

1. Survey 1: [https://arxiv.org/abs/2409.00265](https://arxiv.org/abs/2409.00265)
2. Survey 2: [https://arxiv.org/abs/2412.00800](https://arxiv.org/abs/2412.00800)
3. Survey 3 (GNN): [https://arxiv.org/abs/2306.01958](https://arxiv.org/abs/2306.01958)
